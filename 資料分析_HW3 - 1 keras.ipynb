{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocess(file_name):\n",
    "    df = pd.read_csv(file_name) \n",
    "    # output 第一項看不出漲跌 刪除\n",
    "\n",
    "    Close_Price_data = df['Close Price']\n",
    "    train_y = []\n",
    "    for i in range(len(Close_Price_data)-1):\n",
    "        train_y.append(Close_Price_data[i+1] - Close_Price_data[i])  \n",
    "    for i in range(len(train_y)):\n",
    "        if(train_y[i] >= 0):\n",
    "            train_y[i] = 1 #漲\n",
    "        else:\n",
    "            train_y[i] = 0 #跌\n",
    "    train_y = pd.Series(train_y)\n",
    "    \n",
    "    # input 第一項拿掉\n",
    "    Open_price_data = df['Open Price'][1:]\n",
    "    High_Price_data = df['High Price'][1:]\n",
    "    Low_Price_data = df['Low Price'][1:]\n",
    "    Volume_data = df['Volume'][1:]\n",
    "    Close_Price_data = df['Close Price'][1:]\n",
    "    \n",
    "    #標準化\n",
    "    \n",
    "    normalizer = StandardScaler()\n",
    "    Volume_data_tonum = normalizer.fit_transform(Volume_data.to_numpy().reshape(-1,1))\n",
    "    Volume_data = pd.Series(Volume_data_tonum.reshape(Volume_data.shape))\n",
    "\n",
    "    Open_price_data_tonum = normalizer.fit_transform(Open_price_data.to_numpy().reshape(-1,1))\n",
    "    Open_price_data = pd.Series(Open_price_data_tonum.reshape(Open_price_data.shape))\n",
    "\n",
    "    High_Price_data_tonum = normalizer.fit_transform(High_Price_data.to_numpy().reshape(-1,1))\n",
    "    High_Price_data = pd.Series(High_Price_data_tonum.reshape(High_Price_data.shape))\n",
    "\n",
    "    Low_Price_data_tonum = normalizer.fit_transform(Low_Price_data.to_numpy().reshape(-1,1))\n",
    "    Low_Price_data = pd.Series(Low_Price_data_tonum.reshape(Low_Price_data.shape))\n",
    "\n",
    "    Close_Price_data_tonum = normalizer.fit_transform(Close_Price_data.to_numpy().reshape(-1,1))\n",
    "    Close_Price_data = pd.Series(Close_Price_data_tonum.reshape(Close_Price_data.shape))\n",
    "    \n",
    "    train_x = pd.DataFrame(\n",
    "    {\n",
    "    'Volume':Volume_data,\n",
    "    'Open_price':Open_price_data,\n",
    "    'Close_Price':Close_Price_data,\n",
    "    'High_Price':High_Price_data,\n",
    "    'Low_Price':Low_Price_data\n",
    "    })\n",
    "    \n",
    "    return train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x , train_y = data_preprocess('train.csv')\n",
    "test_x , test_y = data_preprocess('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.7229341581970835\n",
      "test accuracy: 0.8167330677290837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr=LogisticRegression()\n",
    "model_lr.fit(train_x,train_y)\n",
    "\n",
    "pred_train_y = model_lr.predict(train_x)\n",
    "train_acc = accuracy_score(train_y, pred_train_y)\n",
    "pred_test_y = model_lr.predict(test_x)\n",
    "test_acc = accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression 更改參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9346000883782589\n",
      "test accuracy: 0.8326693227091634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model_lr=LogisticRegression(penalty = 'l1',solver = 'liblinear')\n",
    "model_lr.fit(train_x,train_y)\n",
    "\n",
    "pred_train_y = model_lr.predict(train_x)\n",
    "train_acc = accuracy_score(train_y, pred_train_y)\n",
    "pred_test_y = model_lr.predict(test_x)\n",
    "test_acc = accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 2263 samples\n",
      "Epoch 1/10\n",
      "2263/2263 [==============================] - 0s 207us/step - loss: 0.2485 - accuracy: 0.5475 - val_loss: 0.2460 - val_accuracy: 0.5528\n",
      "Epoch 2/10\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.2482 - accuracy: 0.5519 - val_loss: 0.2465 - val_accuracy: 0.5524\n",
      "Epoch 3/10\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.2463 - accuracy: 0.5506 - val_loss: 0.2456 - val_accuracy: 0.5603\n",
      "Epoch 4/10\n",
      "2263/2263 [==============================] - 0s 168us/step - loss: 0.2456 - accuracy: 0.5599 - val_loss: 0.2485 - val_accuracy: 0.5586\n",
      "Epoch 5/10\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.2457 - accuracy: 0.5568 - val_loss: 0.2445 - val_accuracy: 0.5647\n",
      "Epoch 6/10\n",
      "2263/2263 [==============================] - 0s 162us/step - loss: 0.2458 - accuracy: 0.5559 - val_loss: 0.2429 - val_accuracy: 0.5895\n",
      "Epoch 7/10\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.2442 - accuracy: 0.5714 - val_loss: 0.2418 - val_accuracy: 0.5811\n",
      "Epoch 8/10\n",
      "2263/2263 [==============================] - 0s 159us/step - loss: 0.2437 - accuracy: 0.5603 - val_loss: 0.2403 - val_accuracy: 0.5669\n",
      "Epoch 9/10\n",
      "2263/2263 [==============================] - 0s 162us/step - loss: 0.2413 - accuracy: 0.5780 - val_loss: 0.2376 - val_accuracy: 0.5731\n",
      "Epoch 10/10\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.2387 - accuracy: 0.6001 - val_loss: 0.2344 - val_accuracy: 0.6142\n",
      "2263/2263 [==============================] - 0s 19us/step\n",
      "251/251 [==============================] - 0s 32us/step\n",
      "train accuracy: 0.6142289042472839\n",
      "test accuracy: 0.7768924236297607\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(64,input_dim = 5,activation = 'relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(output_dim = 1,activation='sigmoid'))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_acc_all_list = model_nn.fit(train_x, train_y,       #輸入 與 輸出\n",
    "          nb_epoch = 10,          #子代數\n",
    "          batch_size = 10,        #批量大小 一次參考多少的數據\n",
    "          verbose = 1 ,           #是否顯示訓練過程\n",
    "          validation_data=(train_x, train_y)) #拿來預測的資料\n",
    "    \n",
    "\n",
    "train_acc = model_nn.evaluate(train_x,train_y)[1]\n",
    "test_acc = model_nn.evaluate(test_x,test_y)[1]\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network 修改參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 2263 samples\n",
      "Epoch 1/100\n",
      "2263/2263 [==============================] - 1s 275us/step - loss: 0.2495 - accuracy: 0.5316 - val_loss: 0.2467 - val_accuracy: 0.5537\n",
      "Epoch 2/100\n",
      "2263/2263 [==============================] - 0s 207us/step - loss: 0.2479 - accuracy: 0.5382 - val_loss: 0.2458 - val_accuracy: 0.5537\n",
      "Epoch 3/100\n",
      "2263/2263 [==============================] - 0s 189us/step - loss: 0.2471 - accuracy: 0.5537 - val_loss: 0.2460 - val_accuracy: 0.5563\n",
      "Epoch 4/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.2467 - accuracy: 0.5572 - val_loss: 0.2462 - val_accuracy: 0.5608\n",
      "Epoch 5/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.2460 - accuracy: 0.5577 - val_loss: 0.2476 - val_accuracy: 0.5581\n",
      "Epoch 6/100\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.2453 - accuracy: 0.5621 - val_loss: 0.2470 - val_accuracy: 0.5426\n",
      "Epoch 7/100\n",
      "2263/2263 [==============================] - 0s 176us/step - loss: 0.2444 - accuracy: 0.5639 - val_loss: 0.2419 - val_accuracy: 0.5661\n",
      "Epoch 8/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.2427 - accuracy: 0.5776 - val_loss: 0.2371 - val_accuracy: 0.5798\n",
      "Epoch 9/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.2410 - accuracy: 0.5837 - val_loss: 0.2455 - val_accuracy: 0.5382\n",
      "Epoch 10/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.2366 - accuracy: 0.6076 - val_loss: 0.2353 - val_accuracy: 0.6209\n",
      "Epoch 11/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.2246 - accuracy: 0.6465 - val_loss: 0.2259 - val_accuracy: 0.5908\n",
      "Epoch 12/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.2074 - accuracy: 0.6867 - val_loss: 0.1780 - val_accuracy: 0.7282\n",
      "Epoch 13/100\n",
      "2263/2263 [==============================] - 0s 188us/step - loss: 0.1847 - accuracy: 0.7309 - val_loss: 0.1535 - val_accuracy: 0.7954\n",
      "Epoch 14/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.1573 - accuracy: 0.7751 - val_loss: 0.1323 - val_accuracy: 0.8387\n",
      "Epoch 15/100\n",
      "2263/2263 [==============================] - 0s 188us/step - loss: 0.1623 - accuracy: 0.7711 - val_loss: 0.1729 - val_accuracy: 0.7234\n",
      "Epoch 16/100\n",
      "2263/2263 [==============================] - 0s 189us/step - loss: 0.1420 - accuracy: 0.8020 - val_loss: 0.1478 - val_accuracy: 0.7724\n",
      "Epoch 17/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.1261 - accuracy: 0.8188 - val_loss: 0.0953 - val_accuracy: 0.9010\n",
      "Epoch 18/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.1239 - accuracy: 0.8224 - val_loss: 0.1367 - val_accuracy: 0.7707\n",
      "Epoch 19/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.1124 - accuracy: 0.8396 - val_loss: 0.0927 - val_accuracy: 0.8802\n",
      "Epoch 20/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.1196 - accuracy: 0.8330 - val_loss: 0.0998 - val_accuracy: 0.8648\n",
      "Epoch 21/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.1059 - accuracy: 0.8458 - val_loss: 0.1118 - val_accuracy: 0.8285\n",
      "Epoch 22/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.1101 - accuracy: 0.8445 - val_loss: 0.0744 - val_accuracy: 0.9218\n",
      "Epoch 23/100\n",
      "2263/2263 [==============================] - 0s 188us/step - loss: 0.1040 - accuracy: 0.8612 - val_loss: 0.0986 - val_accuracy: 0.8405\n",
      "Epoch 24/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.1078 - accuracy: 0.8475 - val_loss: 0.0830 - val_accuracy: 0.8913\n",
      "Epoch 25/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.1055 - accuracy: 0.8529 - val_loss: 0.1025 - val_accuracy: 0.8387\n",
      "Epoch 26/100\n",
      "2263/2263 [==============================] - 0s 192us/step - loss: 0.0968 - accuracy: 0.8599 - val_loss: 0.1242 - val_accuracy: 0.8303\n",
      "Epoch 27/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0965 - accuracy: 0.8679 - val_loss: 0.0851 - val_accuracy: 0.8864\n",
      "Epoch 28/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.0994 - accuracy: 0.8621 - val_loss: 0.1388 - val_accuracy: 0.7954\n",
      "Epoch 29/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0906 - accuracy: 0.8736 - val_loss: 0.0928 - val_accuracy: 0.8573\n",
      "Epoch 30/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.1058 - accuracy: 0.8506 - val_loss: 0.0796 - val_accuracy: 0.8953\n",
      "Epoch 31/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.1006 - accuracy: 0.8577 - val_loss: 0.0806 - val_accuracy: 0.8833\n",
      "Epoch 32/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.0929 - accuracy: 0.8635 - val_loss: 0.0822 - val_accuracy: 0.8719\n",
      "Epoch 33/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.0924 - accuracy: 0.8670 - val_loss: 0.1161 - val_accuracy: 0.8219\n",
      "Epoch 34/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.0901 - accuracy: 0.8798 - val_loss: 0.0778 - val_accuracy: 0.8838\n",
      "Epoch 35/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0913 - accuracy: 0.8696 - val_loss: 0.1226 - val_accuracy: 0.8215\n",
      "Epoch 36/100\n",
      "2263/2263 [==============================] - 0s 178us/step - loss: 0.1106 - accuracy: 0.8405 - val_loss: 0.0740 - val_accuracy: 0.8966\n",
      "Epoch 37/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.0955 - accuracy: 0.8568 - val_loss: 0.0657 - val_accuracy: 0.9231\n",
      "Epoch 38/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.0942 - accuracy: 0.8710 - val_loss: 0.0966 - val_accuracy: 0.8533\n",
      "Epoch 39/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.0928 - accuracy: 0.8626 - val_loss: 0.1877 - val_accuracy: 0.7446\n",
      "Epoch 40/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.1019 - accuracy: 0.8542 - val_loss: 0.0857 - val_accuracy: 0.8745\n",
      "Epoch 41/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.0918 - accuracy: 0.8758 - val_loss: 0.1290 - val_accuracy: 0.8025\n",
      "Epoch 42/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.1044 - accuracy: 0.8533 - val_loss: 0.1315 - val_accuracy: 0.8175\n",
      "Epoch 43/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0927 - accuracy: 0.8665 - val_loss: 0.0739 - val_accuracy: 0.8953\n",
      "Epoch 44/100\n",
      "2263/2263 [==============================] - 0s 194us/step - loss: 0.0944 - accuracy: 0.8617 - val_loss: 0.0866 - val_accuracy: 0.8604\n",
      "Epoch 45/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.0933 - accuracy: 0.8665 - val_loss: 0.0704 - val_accuracy: 0.8988\n",
      "Epoch 46/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.0969 - accuracy: 0.8586 - val_loss: 0.0653 - val_accuracy: 0.9271\n",
      "Epoch 47/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.1025 - accuracy: 0.8564 - val_loss: 0.0949 - val_accuracy: 0.8551\n",
      "Epoch 48/100\n",
      "2263/2263 [==============================] - 0s 210us/step - loss: 0.0924 - accuracy: 0.8665 - val_loss: 0.0616 - val_accuracy: 0.9218\n",
      "Epoch 49/100\n",
      "2263/2263 [==============================] - 0s 195us/step - loss: 0.0884 - accuracy: 0.8723 - val_loss: 0.0652 - val_accuracy: 0.9174\n",
      "Epoch 50/100\n",
      "2263/2263 [==============================] - 1s 226us/step - loss: 0.0939 - accuracy: 0.8723 - val_loss: 0.0890 - val_accuracy: 0.8652\n",
      "Epoch 51/100\n",
      "2263/2263 [==============================] - 0s 196us/step - loss: 0.0945 - accuracy: 0.8617 - val_loss: 0.0960 - val_accuracy: 0.8537\n",
      "Epoch 52/100\n",
      "2263/2263 [==============================] - 0s 190us/step - loss: 0.0876 - accuracy: 0.8767 - val_loss: 0.0885 - val_accuracy: 0.8665\n",
      "Epoch 53/100\n",
      "2263/2263 [==============================] - 0s 197us/step - loss: 0.0854 - accuracy: 0.8758 - val_loss: 0.1573 - val_accuracy: 0.7919\n",
      "Epoch 54/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.0961 - accuracy: 0.8665 - val_loss: 0.0661 - val_accuracy: 0.9156\n",
      "Epoch 55/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0939 - accuracy: 0.8608 - val_loss: 0.1010 - val_accuracy: 0.8573\n",
      "Epoch 56/100\n",
      "2263/2263 [==============================] - 0s 197us/step - loss: 0.0794 - accuracy: 0.8873 - val_loss: 0.0924 - val_accuracy: 0.8577\n",
      "Epoch 57/100\n",
      "2263/2263 [==============================] - 0s 190us/step - loss: 0.0922 - accuracy: 0.8736 - val_loss: 0.0914 - val_accuracy: 0.8811\n",
      "Epoch 58/100\n",
      "2263/2263 [==============================] - 0s 190us/step - loss: 0.0898 - accuracy: 0.8719 - val_loss: 0.1204 - val_accuracy: 0.8285\n",
      "Epoch 59/100\n",
      "2263/2263 [==============================] - 0s 188us/step - loss: 0.0864 - accuracy: 0.8776 - val_loss: 0.0827 - val_accuracy: 0.8741\n",
      "Epoch 60/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.0910 - accuracy: 0.8683 - val_loss: 0.0776 - val_accuracy: 0.8931\n",
      "Epoch 61/100\n",
      "2263/2263 [==============================] - 0s 189us/step - loss: 0.0920 - accuracy: 0.8692 - val_loss: 0.1027 - val_accuracy: 0.8462\n",
      "Epoch 62/100\n",
      "2263/2263 [==============================] - 0s 191us/step - loss: 0.0878 - accuracy: 0.8727 - val_loss: 0.1013 - val_accuracy: 0.8449\n",
      "Epoch 63/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.0905 - accuracy: 0.8727 - val_loss: 0.1380 - val_accuracy: 0.8078\n",
      "Epoch 64/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0861 - accuracy: 0.8758 - val_loss: 0.0663 - val_accuracy: 0.9081\n",
      "Epoch 65/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.0897 - accuracy: 0.8749 - val_loss: 0.0712 - val_accuracy: 0.8979\n",
      "Epoch 66/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.0860 - accuracy: 0.8736 - val_loss: 0.0874 - val_accuracy: 0.8657\n",
      "Epoch 67/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0878 - accuracy: 0.8710 - val_loss: 0.0723 - val_accuracy: 0.8957\n",
      "Epoch 68/100\n",
      "2263/2263 [==============================] - 0s 195us/step - loss: 0.0892 - accuracy: 0.8758 - val_loss: 0.1619 - val_accuracy: 0.7857\n",
      "Epoch 69/100\n",
      "2263/2263 [==============================] - 0s 203us/step - loss: 0.0904 - accuracy: 0.8701 - val_loss: 0.1179 - val_accuracy: 0.8369\n",
      "Epoch 70/100\n",
      "2263/2263 [==============================] - 0s 204us/step - loss: 0.0768 - accuracy: 0.8913 - val_loss: 0.0688 - val_accuracy: 0.9059\n",
      "Epoch 71/100\n",
      "2263/2263 [==============================] - 0s 209us/step - loss: 0.0802 - accuracy: 0.8856 - val_loss: 0.1686 - val_accuracy: 0.7654\n",
      "Epoch 72/100\n",
      "2263/2263 [==============================] - 0s 207us/step - loss: 0.0868 - accuracy: 0.8763 - val_loss: 0.0775 - val_accuracy: 0.8878\n",
      "Epoch 73/100\n",
      "2263/2263 [==============================] - 0s 204us/step - loss: 0.0905 - accuracy: 0.8692 - val_loss: 0.1067 - val_accuracy: 0.8361\n",
      "Epoch 74/100\n",
      "2263/2263 [==============================] - 1s 229us/step - loss: 0.0857 - accuracy: 0.8798 - val_loss: 0.0612 - val_accuracy: 0.9196\n",
      "Epoch 75/100\n",
      "2263/2263 [==============================] - 0s 196us/step - loss: 0.0959 - accuracy: 0.8617 - val_loss: 0.0854 - val_accuracy: 0.8674\n",
      "Epoch 76/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.0802 - accuracy: 0.8816 - val_loss: 0.0657 - val_accuracy: 0.9129\n",
      "Epoch 77/100\n",
      "2263/2263 [==============================] - 0s 210us/step - loss: 0.0950 - accuracy: 0.8705 - val_loss: 0.1391 - val_accuracy: 0.7972\n",
      "Epoch 78/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.0962 - accuracy: 0.8621 - val_loss: 0.0791 - val_accuracy: 0.8944\n",
      "Epoch 79/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0854 - accuracy: 0.8754 - val_loss: 0.0997 - val_accuracy: 0.8431\n",
      "Epoch 80/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.0946 - accuracy: 0.8679 - val_loss: 0.0932 - val_accuracy: 0.8621\n",
      "Epoch 81/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0855 - accuracy: 0.8772 - val_loss: 0.0878 - val_accuracy: 0.8692\n",
      "Epoch 82/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.0775 - accuracy: 0.8922 - val_loss: 0.0796 - val_accuracy: 0.8825\n",
      "Epoch 83/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0800 - accuracy: 0.8860 - val_loss: 0.0733 - val_accuracy: 0.8948\n",
      "Epoch 84/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0877 - accuracy: 0.8816 - val_loss: 0.1141 - val_accuracy: 0.8263\n",
      "Epoch 85/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.1007 - accuracy: 0.8555 - val_loss: 0.0879 - val_accuracy: 0.8705\n",
      "Epoch 86/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0909 - accuracy: 0.8710 - val_loss: 0.1252 - val_accuracy: 0.8171\n",
      "Epoch 87/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.1000 - accuracy: 0.8612 - val_loss: 0.1155 - val_accuracy: 0.8255\n",
      "Epoch 88/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.0997 - accuracy: 0.8582 - val_loss: 0.1177 - val_accuracy: 0.8078\n",
      "Epoch 89/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.0858 - accuracy: 0.8732 - val_loss: 0.0729 - val_accuracy: 0.8900\n",
      "Epoch 90/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0854 - accuracy: 0.8825 - val_loss: 0.0977 - val_accuracy: 0.8520\n",
      "Epoch 91/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0900 - accuracy: 0.8710 - val_loss: 0.1664 - val_accuracy: 0.7605\n",
      "Epoch 92/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0980 - accuracy: 0.8590 - val_loss: 0.0957 - val_accuracy: 0.8489\n",
      "Epoch 93/100\n",
      "2263/2263 [==============================] - 0s 183us/step - loss: 0.0880 - accuracy: 0.8701 - val_loss: 0.0744 - val_accuracy: 0.8939\n",
      "Epoch 94/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0825 - accuracy: 0.8802 - val_loss: 0.0699 - val_accuracy: 0.9001\n",
      "Epoch 95/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.0883 - accuracy: 0.8749 - val_loss: 0.0724 - val_accuracy: 0.8997\n",
      "Epoch 96/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.0850 - accuracy: 0.8833 - val_loss: 0.1514 - val_accuracy: 0.7870\n",
      "Epoch 97/100\n",
      "2263/2263 [==============================] - 0s 181us/step - loss: 0.0760 - accuracy: 0.8944 - val_loss: 0.0930 - val_accuracy: 0.8555\n",
      "Epoch 98/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.0906 - accuracy: 0.8701 - val_loss: 0.0702 - val_accuracy: 0.8984\n",
      "Epoch 99/100\n",
      "2263/2263 [==============================] - 0s 197us/step - loss: 0.0895 - accuracy: 0.8732 - val_loss: 0.0632 - val_accuracy: 0.9125\n",
      "Epoch 100/100\n",
      "2263/2263 [==============================] - 0s 191us/step - loss: 0.0846 - accuracy: 0.8794 - val_loss: 0.0825 - val_accuracy: 0.8776\n",
      "2263/2263 [==============================] - 0s 18us/step\n",
      "251/251 [==============================] - 0s 28us/step\n",
      "train accuracy: 0.8775961399078369\n",
      "test accuracy: 0.8366534113883972\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(128,input_dim = 5,activation = 'relu'))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(output_dim = 1,activation='sigmoid'))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_acc_all_list = model_nn.fit(train_x, train_y,       #輸入 與 輸出\n",
    "          nb_epoch = 100,          #子代數\n",
    "          batch_size = 10,        #批量大小 一次參考多少的數據\n",
    "          verbose = 1 ,           #是否顯示訓練過程\n",
    "          validation_data=(train_x, train_y)) #拿來預測的資料\n",
    "    \n",
    "\n",
    "train_acc = model_nn.evaluate(train_x,train_y)[1]\n",
    "test_acc = model_nn.evaluate(test_x,test_y)[1]\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network 修改參數 僅調整epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 2263 samples\n",
      "Epoch 1/100\n",
      "2263/2263 [==============================] - 1s 234us/step - loss: 0.2485 - accuracy: 0.5462 - val_loss: 0.2461 - val_accuracy: 0.5656\n",
      "Epoch 2/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.2473 - accuracy: 0.5506 - val_loss: 0.2462 - val_accuracy: 0.5550\n",
      "Epoch 3/100\n",
      "2263/2263 [==============================] - 0s 170us/step - loss: 0.2465 - accuracy: 0.5532 - val_loss: 0.2448 - val_accuracy: 0.5568\n",
      "Epoch 4/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.2447 - accuracy: 0.5625 - val_loss: 0.2448 - val_accuracy: 0.5621\n",
      "Epoch 5/100\n",
      "2263/2263 [==============================] - 0s 199us/step - loss: 0.2448 - accuracy: 0.5612 - val_loss: 0.2484 - val_accuracy: 0.5360\n",
      "Epoch 6/100\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.2457 - accuracy: 0.5586 - val_loss: 0.2415 - val_accuracy: 0.5776\n",
      "Epoch 7/100\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.2429 - accuracy: 0.5696 - val_loss: 0.2401 - val_accuracy: 0.5859\n",
      "Epoch 8/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.2405 - accuracy: 0.5886 - val_loss: 0.2397 - val_accuracy: 0.5749\n",
      "Epoch 9/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.2395 - accuracy: 0.5882 - val_loss: 0.2343 - val_accuracy: 0.6222\n",
      "Epoch 10/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.2375 - accuracy: 0.6023 - val_loss: 0.2369 - val_accuracy: 0.5992\n",
      "Epoch 11/100\n",
      "2263/2263 [==============================] - 0s 178us/step - loss: 0.2328 - accuracy: 0.6248 - val_loss: 0.2317 - val_accuracy: 0.6328\n",
      "Epoch 12/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.2254 - accuracy: 0.6447 - val_loss: 0.2161 - val_accuracy: 0.6832\n",
      "Epoch 13/100\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.2164 - accuracy: 0.6673 - val_loss: 0.2197 - val_accuracy: 0.5877\n",
      "Epoch 14/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.2046 - accuracy: 0.7044 - val_loss: 0.2119 - val_accuracy: 0.7008\n",
      "Epoch 15/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.2002 - accuracy: 0.7203 - val_loss: 0.1872 - val_accuracy: 0.7349\n",
      "Epoch 16/100\n",
      "2263/2263 [==============================] - 0s 168us/step - loss: 0.1844 - accuracy: 0.7494 - val_loss: 0.1765 - val_accuracy: 0.7433\n",
      "Epoch 17/100\n",
      "2263/2263 [==============================] - 0s 158us/step - loss: 0.1741 - accuracy: 0.7680 - val_loss: 0.1608 - val_accuracy: 0.7945\n",
      "Epoch 18/100\n",
      "2263/2263 [==============================] - 0s 161us/step - loss: 0.1670 - accuracy: 0.7751 - val_loss: 0.1566 - val_accuracy: 0.8193\n",
      "Epoch 19/100\n",
      "2263/2263 [==============================] - 0s 178us/step - loss: 0.1528 - accuracy: 0.8131 - val_loss: 0.1585 - val_accuracy: 0.7782\n",
      "Epoch 20/100\n",
      "2263/2263 [==============================] - 0s 168us/step - loss: 0.1471 - accuracy: 0.8197 - val_loss: 0.1351 - val_accuracy: 0.8109\n",
      "Epoch 21/100\n",
      "2263/2263 [==============================] - 0s 186us/step - loss: 0.1527 - accuracy: 0.7950 - val_loss: 0.1406 - val_accuracy: 0.8122\n",
      "Epoch 22/100\n",
      "2263/2263 [==============================] - 0s 208us/step - loss: 0.1416 - accuracy: 0.8109 - val_loss: 0.1244 - val_accuracy: 0.8688\n",
      "Epoch 23/100\n",
      "2263/2263 [==============================] - 0s 217us/step - loss: 0.1304 - accuracy: 0.8480 - val_loss: 0.1201 - val_accuracy: 0.8546\n",
      "Epoch 24/100\n",
      "2263/2263 [==============================] - 0s 176us/step - loss: 0.1252 - accuracy: 0.8431 - val_loss: 0.1101 - val_accuracy: 0.9187\n",
      "Epoch 25/100\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.1323 - accuracy: 0.8188 - val_loss: 0.1603 - val_accuracy: 0.7371\n",
      "Epoch 26/100\n",
      "2263/2263 [==============================] - 0s 175us/step - loss: 0.1227 - accuracy: 0.8387 - val_loss: 0.1314 - val_accuracy: 0.8065\n",
      "Epoch 27/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.1186 - accuracy: 0.8489 - val_loss: 0.1089 - val_accuracy: 0.8833\n",
      "Epoch 28/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.1202 - accuracy: 0.8400 - val_loss: 0.1061 - val_accuracy: 0.8661\n",
      "Epoch 29/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.1122 - accuracy: 0.8586 - val_loss: 0.1067 - val_accuracy: 0.8683\n",
      "Epoch 30/100\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.1140 - accuracy: 0.8595 - val_loss: 0.1384 - val_accuracy: 0.7954\n",
      "Epoch 31/100\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.1070 - accuracy: 0.8679 - val_loss: 0.0911 - val_accuracy: 0.9178\n",
      "Epoch 32/100\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.1101 - accuracy: 0.8506 - val_loss: 0.1166 - val_accuracy: 0.8467\n",
      "Epoch 33/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.1026 - accuracy: 0.8670 - val_loss: 0.1156 - val_accuracy: 0.8246\n",
      "Epoch 34/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.1031 - accuracy: 0.8626 - val_loss: 0.1225 - val_accuracy: 0.8042\n",
      "Epoch 35/100\n",
      "2263/2263 [==============================] - 0s 166us/step - loss: 0.1027 - accuracy: 0.8537 - val_loss: 0.0988 - val_accuracy: 0.8643\n",
      "Epoch 36/100\n",
      "2263/2263 [==============================] - 0s 163us/step - loss: 0.1029 - accuracy: 0.8573 - val_loss: 0.0860 - val_accuracy: 0.8975\n",
      "Epoch 37/100\n",
      "2263/2263 [==============================] - 0s 157us/step - loss: 0.0992 - accuracy: 0.8652 - val_loss: 0.0857 - val_accuracy: 0.9041\n",
      "Epoch 38/100\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.1065 - accuracy: 0.8551 - val_loss: 0.0999 - val_accuracy: 0.8736\n",
      "Epoch 39/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.1056 - accuracy: 0.8564 - val_loss: 0.0940 - val_accuracy: 0.8807\n",
      "Epoch 40/100\n",
      "2263/2263 [==============================] - 0s 159us/step - loss: 0.1096 - accuracy: 0.8462 - val_loss: 0.1584 - val_accuracy: 0.7609\n",
      "Epoch 41/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.1024 - accuracy: 0.8604 - val_loss: 0.2026 - val_accuracy: 0.7079\n",
      "Epoch 42/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.1004 - accuracy: 0.8714 - val_loss: 0.0877 - val_accuracy: 0.8886\n",
      "Epoch 43/100\n",
      "2263/2263 [==============================] - 0s 163us/step - loss: 0.0950 - accuracy: 0.8648 - val_loss: 0.1097 - val_accuracy: 0.8365\n",
      "Epoch 44/100\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.1156 - accuracy: 0.8400 - val_loss: 0.0874 - val_accuracy: 0.8802\n",
      "Epoch 45/100\n",
      "2263/2263 [==============================] - 0s 172us/step - loss: 0.0949 - accuracy: 0.8696 - val_loss: 0.1760 - val_accuracy: 0.7543\n",
      "Epoch 46/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.0992 - accuracy: 0.8643 - val_loss: 0.0776 - val_accuracy: 0.9156\n",
      "Epoch 47/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.0943 - accuracy: 0.8710 - val_loss: 0.2027 - val_accuracy: 0.7128\n",
      "Epoch 48/100\n",
      "2263/2263 [==============================] - 0s 178us/step - loss: 0.1061 - accuracy: 0.8595 - val_loss: 0.0721 - val_accuracy: 0.9258\n",
      "Epoch 49/100\n",
      "2263/2263 [==============================] - 0s 159us/step - loss: 0.0921 - accuracy: 0.8727 - val_loss: 0.2353 - val_accuracy: 0.6920\n",
      "Epoch 50/100\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.0956 - accuracy: 0.8665 - val_loss: 0.0764 - val_accuracy: 0.9103\n",
      "Epoch 51/100\n",
      "2263/2263 [==============================] - 0s 176us/step - loss: 0.0870 - accuracy: 0.8811 - val_loss: 0.0875 - val_accuracy: 0.8816\n",
      "Epoch 52/100\n",
      "2263/2263 [==============================] - 0s 201us/step - loss: 0.0956 - accuracy: 0.8674 - val_loss: 0.0943 - val_accuracy: 0.8696\n",
      "Epoch 53/100\n",
      "2263/2263 [==============================] - 0s 187us/step - loss: 0.0948 - accuracy: 0.8701 - val_loss: 0.0778 - val_accuracy: 0.8966\n",
      "Epoch 54/100\n",
      "2263/2263 [==============================] - 0s 192us/step - loss: 0.1112 - accuracy: 0.8418 - val_loss: 0.1294 - val_accuracy: 0.7945\n",
      "Epoch 55/100\n",
      "2263/2263 [==============================] - 0s 182us/step - loss: 0.0870 - accuracy: 0.8900 - val_loss: 0.0979 - val_accuracy: 0.8758\n",
      "Epoch 56/100\n",
      "2263/2263 [==============================] - 0s 164us/step - loss: 0.0897 - accuracy: 0.8780 - val_loss: 0.0802 - val_accuracy: 0.8847\n",
      "Epoch 57/100\n",
      "2263/2263 [==============================] - 0s 170us/step - loss: 0.0857 - accuracy: 0.8856 - val_loss: 0.1046 - val_accuracy: 0.8520\n",
      "Epoch 58/100\n",
      "2263/2263 [==============================] - 0s 177us/step - loss: 0.0867 - accuracy: 0.8820 - val_loss: 0.0806 - val_accuracy: 0.9054\n",
      "Epoch 59/100\n",
      "2263/2263 [==============================] - 0s 158us/step - loss: 0.0902 - accuracy: 0.8772 - val_loss: 0.0769 - val_accuracy: 0.9046\n",
      "Epoch 60/100\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.0811 - accuracy: 0.8904 - val_loss: 0.0770 - val_accuracy: 0.8931\n",
      "Epoch 61/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.0904 - accuracy: 0.8696 - val_loss: 0.0741 - val_accuracy: 0.8944\n",
      "Epoch 62/100\n",
      "2263/2263 [==============================] - 0s 157us/step - loss: 0.0858 - accuracy: 0.8719 - val_loss: 0.0940 - val_accuracy: 0.8590\n",
      "Epoch 63/100\n",
      "2263/2263 [==============================] - 0s 157us/step - loss: 0.0860 - accuracy: 0.8856 - val_loss: 0.0716 - val_accuracy: 0.9063\n",
      "Epoch 64/100\n",
      "2263/2263 [==============================] - 0s 162us/step - loss: 0.0901 - accuracy: 0.8776 - val_loss: 0.1218 - val_accuracy: 0.8109\n",
      "Epoch 65/100\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.0875 - accuracy: 0.8741 - val_loss: 0.0868 - val_accuracy: 0.8710\n",
      "Epoch 66/100\n",
      "2263/2263 [==============================] - 0s 162us/step - loss: 0.0930 - accuracy: 0.8701 - val_loss: 0.0835 - val_accuracy: 0.8802\n",
      "Epoch 67/100\n",
      "2263/2263 [==============================] - 0s 158us/step - loss: 0.0889 - accuracy: 0.8696 - val_loss: 0.1007 - val_accuracy: 0.8462\n",
      "Epoch 68/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.0857 - accuracy: 0.8745 - val_loss: 0.0807 - val_accuracy: 0.8825\n",
      "Epoch 69/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.0770 - accuracy: 0.8957 - val_loss: 0.0875 - val_accuracy: 0.8807\n",
      "Epoch 70/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.0962 - accuracy: 0.8692 - val_loss: 0.0972 - val_accuracy: 0.8586\n",
      "Epoch 71/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.0967 - accuracy: 0.8626 - val_loss: 0.0784 - val_accuracy: 0.8909\n",
      "Epoch 72/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.0808 - accuracy: 0.8891 - val_loss: 0.0706 - val_accuracy: 0.9107\n",
      "Epoch 73/100\n",
      "2263/2263 [==============================] - 0s 156us/step - loss: 0.0820 - accuracy: 0.8856 - val_loss: 0.0641 - val_accuracy: 0.9271\n",
      "Epoch 74/100\n",
      "2263/2263 [==============================] - 0s 156us/step - loss: 0.0975 - accuracy: 0.8785 - val_loss: 0.1136 - val_accuracy: 0.8343\n",
      "Epoch 75/100\n",
      "2263/2263 [==============================] - 0s 161us/step - loss: 0.0987 - accuracy: 0.8564 - val_loss: 0.0809 - val_accuracy: 0.8833\n",
      "Epoch 76/100\n",
      "2263/2263 [==============================] - 0s 161us/step - loss: 0.0938 - accuracy: 0.8657 - val_loss: 0.1062 - val_accuracy: 0.8436\n",
      "Epoch 77/100\n",
      "2263/2263 [==============================] - 0s 163us/step - loss: 0.0908 - accuracy: 0.8692 - val_loss: 0.0676 - val_accuracy: 0.9107\n",
      "Epoch 78/100\n",
      "2263/2263 [==============================] - 0s 180us/step - loss: 0.0897 - accuracy: 0.8749 - val_loss: 0.0670 - val_accuracy: 0.9147\n",
      "Epoch 79/100\n",
      "2263/2263 [==============================] - 0s 178us/step - loss: 0.0899 - accuracy: 0.8732 - val_loss: 0.0873 - val_accuracy: 0.8749\n",
      "Epoch 80/100\n",
      "2263/2263 [==============================] - 0s 179us/step - loss: 0.0940 - accuracy: 0.8670 - val_loss: 0.1028 - val_accuracy: 0.8577\n",
      "Epoch 81/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.1024 - accuracy: 0.8568 - val_loss: 0.0811 - val_accuracy: 0.8904\n",
      "Epoch 82/100\n",
      "2263/2263 [==============================] - 0s 163us/step - loss: 0.0816 - accuracy: 0.8851 - val_loss: 0.0646 - val_accuracy: 0.9227\n",
      "Epoch 83/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.0944 - accuracy: 0.8701 - val_loss: 0.1195 - val_accuracy: 0.8277\n",
      "Epoch 84/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.0839 - accuracy: 0.8873 - val_loss: 0.0673 - val_accuracy: 0.9196\n",
      "Epoch 85/100\n",
      "2263/2263 [==============================] - 0s 192us/step - loss: 0.0813 - accuracy: 0.8847 - val_loss: 0.1930 - val_accuracy: 0.7428\n",
      "Epoch 86/100\n",
      "2263/2263 [==============================] - 1s 266us/step - loss: 0.0853 - accuracy: 0.8807 - val_loss: 0.0756 - val_accuracy: 0.8997\n",
      "Epoch 87/100\n",
      "2263/2263 [==============================] - 0s 189us/step - loss: 0.0861 - accuracy: 0.8869 - val_loss: 0.0730 - val_accuracy: 0.9015\n",
      "Epoch 88/100\n",
      "2263/2263 [==============================] - 0s 203us/step - loss: 0.0796 - accuracy: 0.8953 - val_loss: 0.0818 - val_accuracy: 0.8763\n",
      "Epoch 89/100\n",
      "2263/2263 [==============================] - 0s 169us/step - loss: 0.0837 - accuracy: 0.8789 - val_loss: 0.0648 - val_accuracy: 0.9191\n",
      "Epoch 90/100\n",
      "2263/2263 [==============================] - 0s 174us/step - loss: 0.0907 - accuracy: 0.8741 - val_loss: 0.1159 - val_accuracy: 0.8250\n",
      "Epoch 91/100\n",
      "2263/2263 [==============================] - 0s 163us/step - loss: 0.0790 - accuracy: 0.8900 - val_loss: 0.1123 - val_accuracy: 0.8299\n",
      "Epoch 92/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.0915 - accuracy: 0.8714 - val_loss: 0.0893 - val_accuracy: 0.8789\n",
      "Epoch 93/100\n",
      "2263/2263 [==============================] - 0s 170us/step - loss: 0.0803 - accuracy: 0.8851 - val_loss: 0.0663 - val_accuracy: 0.9196\n",
      "Epoch 94/100\n",
      "2263/2263 [==============================] - 0s 166us/step - loss: 0.0887 - accuracy: 0.8780 - val_loss: 0.0765 - val_accuracy: 0.8922\n",
      "Epoch 95/100\n",
      "2263/2263 [==============================] - 0s 167us/step - loss: 0.0821 - accuracy: 0.8882 - val_loss: 0.0890 - val_accuracy: 0.8626\n",
      "Epoch 96/100\n",
      "2263/2263 [==============================] - 0s 160us/step - loss: 0.0795 - accuracy: 0.8886 - val_loss: 0.0951 - val_accuracy: 0.8604\n",
      "Epoch 97/100\n",
      "2263/2263 [==============================] - 0s 173us/step - loss: 0.0880 - accuracy: 0.8692 - val_loss: 0.1030 - val_accuracy: 0.8533\n",
      "Epoch 98/100\n",
      "2263/2263 [==============================] - 0s 171us/step - loss: 0.0862 - accuracy: 0.8767 - val_loss: 0.0752 - val_accuracy: 0.8873\n",
      "Epoch 99/100\n",
      "2263/2263 [==============================] - 0s 165us/step - loss: 0.0824 - accuracy: 0.8864 - val_loss: 0.0745 - val_accuracy: 0.8939\n",
      "Epoch 100/100\n",
      "2263/2263 [==============================] - 0s 169us/step - loss: 0.0949 - accuracy: 0.8652 - val_loss: 0.0782 - val_accuracy: 0.8953\n",
      "2263/2263 [==============================] - 0s 17us/step\n",
      "251/251 [==============================] - 0s 28us/step\n",
      "train accuracy: 0.8952717781066895\n",
      "test accuracy: 0.8366534113883972\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(64,input_dim = 5,activation = 'relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(output_dim = 1,activation='sigmoid'))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_acc_all_list = model_nn.fit(train_x, train_y,       #輸入 與 輸出\n",
    "          nb_epoch = 100,          #子代數\n",
    "          batch_size = 10,        #批量大小 一次參考多少的數據\n",
    "          verbose = 1 ,           #是否顯示訓練過程\n",
    "          validation_data=(train_x, train_y)) #拿來預測的資料\n",
    "    \n",
    "\n",
    "train_acc = model_nn.evaluate(train_x,train_y)[1]\n",
    "test_acc = model_nn.evaluate(test_x,test_y)[1]\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network 修改參數 僅調整隱藏層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2263 samples, validate on 2263 samples\n",
      "Epoch 1/10\n",
      "2263/2263 [==============================] - 1s 261us/step - loss: 0.2491 - accuracy: 0.5471 - val_loss: 0.2471 - val_accuracy: 0.5506\n",
      "Epoch 2/10\n",
      "2263/2263 [==============================] - 0s 188us/step - loss: 0.2487 - accuracy: 0.5435 - val_loss: 0.2459 - val_accuracy: 0.5519\n",
      "Epoch 3/10\n",
      "2263/2263 [==============================] - 0s 184us/step - loss: 0.2476 - accuracy: 0.5497 - val_loss: 0.2488 - val_accuracy: 0.5537\n",
      "Epoch 4/10\n",
      "2263/2263 [==============================] - 0s 191us/step - loss: 0.2470 - accuracy: 0.5502 - val_loss: 0.2458 - val_accuracy: 0.5493\n",
      "Epoch 5/10\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.2462 - accuracy: 0.5621 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 6/10\n",
      "2263/2263 [==============================] - 0s 185us/step - loss: 0.2460 - accuracy: 0.5581 - val_loss: 0.2435 - val_accuracy: 0.5630\n",
      "Epoch 7/10\n",
      "2263/2263 [==============================] - 1s 234us/step - loss: 0.2454 - accuracy: 0.5599 - val_loss: 0.2436 - val_accuracy: 0.5687\n",
      "Epoch 8/10\n",
      "2263/2263 [==============================] - 0s 215us/step - loss: 0.2428 - accuracy: 0.5678 - val_loss: 0.2505 - val_accuracy: 0.5568\n",
      "Epoch 9/10\n",
      "2263/2263 [==============================] - 0s 190us/step - loss: 0.2446 - accuracy: 0.5643 - val_loss: 0.2342 - val_accuracy: 0.6195\n",
      "Epoch 10/10\n",
      "2263/2263 [==============================] - 0s 189us/step - loss: 0.2377 - accuracy: 0.5806 - val_loss: 0.2316 - val_accuracy: 0.6310\n",
      "2263/2263 [==============================] - 0s 17us/step\n",
      "251/251 [==============================] - 0s 32us/step\n",
      "train accuracy: 0.6310207843780518\n",
      "test accuracy: 0.7768924236297607\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(128,input_dim = 5,activation = 'relu'))\n",
    "model_nn.add(Dense(64, activation='relu'))\n",
    "model_nn.add(Dense(32, activation='relu'))\n",
    "model_nn.add(Dense(output_dim = 1,activation='sigmoid'))\n",
    "model_nn.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_acc_all_list = model_nn.fit(train_x, train_y,       #輸入 與 輸出\n",
    "          nb_epoch = 10,          #子代數\n",
    "          batch_size = 10,        #批量大小 一次參考多少的數據\n",
    "          verbose = 1 ,           #是否顯示訓練過程\n",
    "          validation_data=(train_x, train_y)) #拿來預測的資料\n",
    "    \n",
    "\n",
    "train_acc = model_nn.evaluate(train_x,train_y)[1]\n",
    "test_acc = model_nn.evaluate(test_x,test_y)[1]\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.5638532920901458\n",
      "test accuracy: 0.5099601593625498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(\n",
    "        criterion='gini',                           \n",
    "        max_depth=2,                                \n",
    "        max_leaf_nodes=2**4,\n",
    "        random_state =2020) \n",
    "model_dt.fit(train_x,train_y)\n",
    "\n",
    "pred_train_y = model_dt.predict(train_x)\n",
    "train_acc = accuracy_score(train_y, pred_train_y)\n",
    "pred_test_y = model_dt.predict(test_x)\n",
    "test_acc = accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree 調整參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.6853733981440565\n",
      "test accuracy: 0.5697211155378487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(\n",
    "        criterion='gini', \n",
    "        splitter = 'best',\n",
    "        max_depth=10,                                \n",
    "        max_leaf_nodes=2**8,\n",
    "        random_state =2020) \n",
    "model_dt.fit(train_x,train_y)\n",
    "\n",
    "pred_train_y = model_dt.predict(train_x)\n",
    "train_acc = accuracy_score(train_y, pred_train_y)\n",
    "pred_test_y = model_dt.predict(test_x)\n",
    "test_acc = accuracy_score(test_y, pred_test_y)\n",
    "\n",
    "print('train accuracy: {}'.format(train_acc)) \n",
    "print('test accuracy: {}'.format(test_acc)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
